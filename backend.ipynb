{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMdgBvMzN+xOWYArmccgB1q",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ManojithBhat/4th-Sem-Lab-programs/blob/main/backend.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OA4yvB8tXkXy"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip -q install --upgrade folium\n",
        "!apt install libspatialindex-dev\n",
        "!pip -q install rtree\n",
        "!pip -q install geopandas\n",
        "!pip -q install geojson\n",
        "!pip -q install geemap==0.17.3\n",
        "!pip -q uninstall tornado -y\n",
        "!yes | pip install tornado==5.1.0\n",
        "!pip -q install rasterio\n",
        "!pip -q install tqdm\n",
        "!pip -q install eeconvert\n",
        "!pip install fastapi uvicorn pyngrok pydantic"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard imports\n",
        "import os\n",
        "from tqdm.notebook import tqdm\n",
        "import requests\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# Geospatial processing packages\n",
        "import geopandas as gpd\n",
        "import geojson\n",
        "\n",
        "import shapely\n",
        "import rasterio as rio\n",
        "from rasterio.plot import show\n",
        "import rasterio.mask\n",
        "from shapely.geometry import box\n",
        "from fastapi.middleware.cors import CORSMiddleware\n",
        "\n",
        "# Mapping and plotting libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as cl\n",
        "import ee\n",
        "import eeconvert as eec\n",
        "import geemap\n",
        "import geemap.eefolium as emap\n",
        "import folium\n",
        "\n",
        "# Deep learning libraries\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms\n",
        "\n",
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "import uvicorn\n",
        "from typing import List, Dict\n",
        "from pydantic import BaseModel\n",
        "import time\n",
        "import asyncio\n",
        "import logging\n",
        "from collections import Counter\n",
        "import uuid"
      ],
      "metadata": {
        "id": "bJzb-nJwYU4a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "WR9OsHh5YtRS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90f02725-b81a-4d7a-b3b6-66e1da45c64d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ee.Authenticate()\n",
        "ee.Initialize(project=\"lulc-sde-el\")"
      ],
      "metadata": {
        "id": "xXB3_I3mY0U9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app = FastAPI()\n",
        "app.add_middleware(\n",
        "    CORSMiddleware,\n",
        "    allow_origins=[\"*\"],\n",
        "    allow_credentials=True,\n",
        "    allow_methods=[\"*\"],\n",
        "    allow_headers=[\"*\"],\n",
        ")"
      ],
      "metadata": {
        "id": "iBtI7nclY3l7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CoordinatePoint(BaseModel):\n",
        "    lat: float\n",
        "    lng: float\n",
        "\n",
        "class InputData(BaseModel):\n",
        "    data: List[CoordinatePoint]\n",
        "    shape_name: str\n"
      ],
      "metadata": {
        "id": "RHXaJ2JoY7CR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logging.basicConfig(\n",
        "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
        "    level=logging.DEBUG\n",
        ")\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "M38qHTpyxUxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    'AnnualCrop',\n",
        "    'Forest',\n",
        "    'HerbaceousVegetation',\n",
        "    'Highway',\n",
        "    'Industrial',\n",
        "    'Pasture',\n",
        "    'PermanentCrop',\n",
        "    'Residential',\n",
        "    'River',\n",
        "    'SeaLake'\n",
        "]\n",
        "\n",
        "# Colors for visualization\n",
        "colors = {\n",
        "    'AnnualCrop': 'lightgreen',\n",
        "    'Forest': 'forestgreen',\n",
        "    'HerbaceousVegetation': 'yellowgreen',\n",
        "    'Highway': 'gray',\n",
        "    'Industrial': 'red',\n",
        "    'Pasture': 'mediumseagreen',\n",
        "    'PermanentCrop': 'chartreuse',\n",
        "    'Residential': 'magenta',\n",
        "    'River': 'dodgerblue',\n",
        "    'SeaLake': 'blue'\n",
        "}"
      ],
      "metadata": {
        "id": "Lt68WHCpv-d4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Model transformation\n",
        "imagenet_mean, imagenet_std = [0.485, 0.456, 0.406], [0.229, 0.224, 0.225]\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])"
      ],
      "metadata": {
        "id": "vYewe6zouxHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_PATH = './drive/My Drive/Colab Notebooks/models/best_model.pth'\n",
        "\n",
        "def load_model(model_path: str):\n",
        "    logger.info(f\"Loading model from {model_path}\")\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    num_ftrs = model.fc.in_features\n",
        "    model.fc = torch.nn.Linear(num_ftrs, len(classes))\n",
        "    model.load_state_dict(torch.load(model_path, map_location=device))\n",
        "    model.eval().to(device)\n",
        "    logger.info(\"Model loaded and set to eval mode\")\n",
        "    return model\n",
        "\n",
        "model = load_model(MODEL_PATH)"
      ],
      "metadata": {
        "id": "XIHYrqQCxSIs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_image(region, product='COPERNICUS/S2',\n",
        "                   min_date='2019-01-01', max_date='2020-01-01',\n",
        "                   range_min=0, range_max=2000, cloud_pct=10):\n",
        "    logger.debug(\"Starting image generation\")\n",
        "    image = ee.ImageCollection(product)\n",
        "    image = image.filterBounds(region)\n",
        "    logger.debug(f\"Filtered bounds with region: {region.getInfo()['coordinates']}\")\n",
        "    image = image.filterDate(min_date, max_date)\n",
        "    image = image.filter(ee.Filter.lt(\"CLOUDY_PIXEL_PERCENTAGE\", cloud_pct))\n",
        "    logger.debug(f\"Filtered images between {min_date} and {max_date} with <{cloud_pct}% clouds\")\n",
        "    image = image.median()\n",
        "    image = image.visualize(bands=['B4', 'B3', 'B2'], min=range_min, max=range_max)\n",
        "    logger.debug(\"RGB visualization applied to image\")\n",
        "    clipped = image.clip(region)\n",
        "    logger.debug(\"Image clipped to region\")\n",
        "    return clipped\n",
        "\n",
        "# Export to Drive with poll\n",
        "def export_image(image, filename, region, folder):\n",
        "    logger.info(f\"Exporting image {filename} to Drive folder {folder}\")\n",
        "    task = ee.batch.Export.image.toDrive(\n",
        "        image=image,\n",
        "        driveFolder=folder,\n",
        "        description=filename,\n",
        "        fileNamePrefix=filename,\n",
        "        scale=10,\n",
        "        region=region.geometry(),\n",
        "        fileFormat='GeoTIFF',\n",
        "        crs='EPSG:4326',\n",
        "        maxPixels=9e6\n",
        "    )\n",
        "    task.start()\n",
        "    while True:\n",
        "        status = task.status()['state']\n",
        "        logger.debug(f\"Image export task status: {status}\")\n",
        "        if status == 'COMPLETED':\n",
        "            logger.info(\"Image export completed\")\n",
        "            break\n",
        "        if status in ('FAILED', 'CANCELLED'):\n",
        "            logger.error(f\"Image export failed: {task.status()}\")\n",
        "            raise RuntimeError(f\"Export task ended with status {status}\")\n",
        "        time.sleep(5)\n",
        "    return task\n",
        "\n",
        "# Generate tiles\n",
        "def generate_tiles(image_file, output_file, area_str, size=64):\n",
        "    logger.info(f\"Generating {size}x{size} tiles for {image_file}\")\n",
        "    raster = rio.open(image_file)\n",
        "    width, height = raster.shape\n",
        "    geo_dict = {'id': [], 'geometry': []}\n",
        "    idx = 0\n",
        "    for w in range(0, width, size):\n",
        "        for h in range(0, height, size):\n",
        "            window = rio.windows.Window(h, w, size, size)\n",
        "            bbox = rio.windows.bounds(window, raster.transform)\n",
        "            geom = box(*bbox)\n",
        "            uid = f\"{area_str.lower().replace(' ', '_')}-{idx}\"\n",
        "            geo_dict['id'].append(uid)\n",
        "            geo_dict['geometry'].append(geom)\n",
        "            idx += 1\n",
        "    tiles = gpd.GeoDataFrame(geo_dict, crs='EPSG:4326')\n",
        "    tiles.to_file(output_file, driver=\"GeoJSON\")\n",
        "    raster.close()\n",
        "    logger.info(f\"Saved {len(tiles)} tiles to {output_file}\")\n",
        "    return tiles\n",
        "\n",
        "# Predict crop on one tile\n",
        "def predict_crop(image_path, shapes, classes, model):\n",
        "    try:\n",
        "        with rio.open(image_path) as src:\n",
        "            out_image, out_transform = rio.mask.mask(src, shapes, crop=True)\n",
        "        logger.debug(\"Cropped image for prediction\")\n",
        "        # Remove zero border\n",
        "        _, xnz, ynz = np.nonzero(out_image)\n",
        "        cropped = out_image[:, xnz.min():xnz.max(), ynz.min():ynz.max()]\n",
        "        # Save to temp file\n",
        "        temp_file = f\"temp_{uuid.uuid4().hex}.tif\"\n",
        "        meta = src.meta.copy()\n",
        "        meta.update({\"height\": cropped.shape[1],\n",
        "                     \"width\": cropped.shape[2],\n",
        "                     \"transform\": out_transform})\n",
        "        with rio.open(temp_file, 'w', **meta) as dest:\n",
        "            dest.write(cropped)\n",
        "        logger.debug(f\"Written temp file {temp_file}\")\n",
        "        img = Image.open(temp_file)\n",
        "        inp = transform(img).unsqueeze(0).to(device)\n",
        "        out = model(inp)\n",
        "        _, pred = torch.max(out, 1)\n",
        "        label = classes[pred.item()]\n",
        "        os.remove(temp_file)\n",
        "        logger.debug(f\"Prediction: {label}\")\n",
        "        return label\n",
        "    except Exception as e:\n",
        "        logger.error(f\"predict_crop error: {e}\")\n",
        "        raise\n",
        "\n",
        "@app.post(\"/predict\")\n",
        "def predict(input_data: InputData):\n",
        "    try:\n",
        "        coords = [[p.lng, p.lat] for p in input_data.data]\n",
        "        polygon = ee.Geometry.Polygon([coords])\n",
        "        region = ee.FeatureCollection([ee.Feature(polygon)])\n",
        "        shape_name = input_data.shape_name\n",
        "        output_dir = \"/content/drive/My Drive/google_pic\"\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "        # Image generation and export\n",
        "        image = generate_image(region)\n",
        "        export_image(image, shape_name, region, 'google_pic')\n",
        "        tif_path = os.path.join(output_dir, f\"{shape_name}.tif\")\n",
        "\n",
        "        # Boundary via getInfo\n",
        "        boundary_geo = polygon.getInfo()['coordinates']\n",
        "        boundary_file = os.path.join(output_dir, f\"{shape_name}_boundary.geojson\")\n",
        "        with open(boundary_file, 'w') as bf:\n",
        "            json.dump({'type':'Polygon','coordinates': boundary_geo}, bf)\n",
        "        boundary = gpd.read_file(boundary_file)\n",
        "        logger.info(\"Boundary GeoJSON loaded\")\n",
        "\n",
        "        # Tiles\n",
        "        tiles_file = os.path.join(output_dir, f\"{shape_name}.geojson\")\n",
        "        tiles = generate_tiles(tif_path, tiles_file, shape_name)\n",
        "        tiles = gpd.sjoin(tiles, boundary, predicate='within')\n",
        "        logger.info(f\"Filtered tiles count: {len(tiles)}\")\n",
        "\n",
        "        # Predictions\n",
        "        labels = []\n",
        "        for _idx in tqdm(range(len(tiles)), desc=\"Predicting tiles\"):\n",
        "            labels.append(predict_crop(tif_path, [tiles.geometry.iloc[_idx]], classes, model))\n",
        "        tiles['pred'] = labels\n",
        "\n",
        "        # Compute distribution\n",
        "        tile_counts = Counter(labels)\n",
        "        total = len(labels)\n",
        "        class_pct = {cls: (tile_counts.get(cls,0)/total)*100 for cls in classes}\n",
        "        logger.info(f\"Class percentages: {class_pct}\")\n",
        "\n",
        "        # Save preds\n",
        "        preds_file = os.path.join(output_dir, f\"{shape_name}_preds.geojson\")\n",
        "        tiles.to_file(preds_file, driver=\"GeoJSON\")\n",
        "\n",
        "        # Return payload\n",
        "        return {\n",
        "            \"status\": \"success\",\n",
        "            \"shape_name\": shape_name,\n",
        "            \"class_distribution\": {cls: {\"count\": tile_counts.get(cls,0), \"percent\": class_pct[cls]} for cls in classes},\n",
        "            \"predictions_file\": preds_file\n",
        "        }\n",
        "    except Exception as e:\n",
        "        logger.exception(\"Error in /predict\")\n",
        "        raise HTTPException(status_code=500, detail=str(e))\n",
        "\n",
        "@app.on_event(\"startup\")\n",
        "async def startup_event():\n",
        "    # Setup ngrok\n",
        "    # Note: You'll need an ngrok authtoken for this to work\n",
        "    import nest_asyncio\n",
        "    ngrok.set_auth_token(\"<enter the ngrok api here>\")\n",
        "\n",
        "    public_url = ngrok.connect(8000)\n",
        "    print(\"FastAPI running on:\", public_url)"
      ],
      "metadata": {
        "id": "vKl-DwncZZ2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "024706db-da4d-4a19-f05c-670f4ef0e02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-b5027f421af5>:153: DeprecationWarning: \n",
            "        on_event is deprecated, use lifespan event handlers instead.\n",
            "\n",
            "        Read more about it in the\n",
            "        [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).\n",
            "        \n",
            "  @app.on_event(\"startup\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "1VtEYnFW8Wy_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ],
      "metadata": {
        "id": "cslpX-WkZaxP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 925
        },
        "outputId": "146b87bc-33f5-45bf-96e3-211d3f30a4ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:     Started server process [313]\n",
            "INFO:     Waiting for application startup.\n",
            "WARNING:pyngrok.process.ngrok:t=2025-05-12T18:39:19+0000 lvl=warn msg=\"failed to start tunnel\" pg=/api/tunnels id=21fc948171fc02d1 err=\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2x0Vj5Noy5A5oV6e1r1H3M8hNAB, tn_2x0Vj2QJyuCP1NZhev5rj4uCRYl, tn_2x0Vj5Lfk8HQmcRDU69H21hNDQf\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"\n",
            "ERROR:    Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 622, in api_request\n",
            "    response = urlopen(request, encoded_data, timeout)\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/urllib/request.py\", line 216, in urlopen\n",
            "    return opener.open(url, data, timeout)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/urllib/request.py\", line 525, in open\n",
            "    response = meth(req, response)\n",
            "               ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/urllib/request.py\", line 634, in http_response\n",
            "    response = self.parent.error(\n",
            "               ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/urllib/request.py\", line 563, in error\n",
            "    return self._call_chain(*args)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/urllib/request.py\", line 496, in _call_chain\n",
            "    result = func(*args)\n",
            "             ^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/urllib/request.py\", line 643, in http_error_default\n",
            "    raise HTTPError(req.full_url, code, msg, hdrs, fp)\n",
            "urllib.error.HTTPError: HTTP Error 502: Bad Gateway\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 692, in lifespan\n",
            "    async with self.lifespan_context(app) as maybe_state:\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 569, in __aenter__\n",
            "    await self._router.startup()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/starlette/routing.py\", line 669, in startup\n",
            "    await handler()\n",
            "  File \"<ipython-input-9-eb42ac8a1443>\", line 341, in startup_event\n",
            "    public_url = ngrok.connect(8000)\n",
            "                 ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 389, in connect\n",
            "    tunnel = NgrokTunnel(api_request(f\"{api_url}/api/tunnels\", method=\"POST\", data=options,\n",
            "                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pyngrok/ngrok.py\", line 643, in api_request\n",
            "    raise PyngrokNgrokHTTPError(f\"ngrok client exception, API returned {status_code}: {response_data}\",\n",
            "pyngrok.exception.PyngrokNgrokHTTPError: ngrok client exception, API returned 502: {\"error_code\":103,\"status_code\":502,\"msg\":\"failed to start tunnel\",\"details\":{\"err\":\"failed to start tunnel: Your account may not run more than 3 tunnels over a single ngrok agent session.\\nThe tunnels already running on this session are:\\ntn_2x0Vj5Noy5A5oV6e1r1H3M8hNAB, tn_2x0Vj2QJyuCP1NZhev5rj4uCRYl, tn_2x0Vj5Lfk8HQmcRDU69H21hNDQf\\n\\r\\n\\r\\nERR_NGROK_324\\r\\n\"}}\n",
            "\n",
            "\n",
            "ERROR:    Application startup failed. Exiting.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "3",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 3\n"
          ]
        }
      ]
    }
  ]
}